---
title: Estilo de arquitectura de macrodatos
description: Describe las ventajas, las dificultades y los procedimientos recomendados para las arquitecturas de macrodatos en Azure.
author: MikeWasson
ms.openlocfilehash: 4e8b58d5fa0f6a441d70e05ec7d6a0e668712563
ms.sourcegitcommit: b0482d49aab0526be386837702e7724c61232c60
ms.translationtype: HT
ms.contentlocale: es-ES
ms.lasthandoff: 11/14/2017
ms.locfileid: "24540895"
---
# <a name="big-data-architecture-style"></a><span data-ttu-id="d635a-103">Estilo de arquitectura de macrodatos</span><span class="sxs-lookup"><span data-stu-id="d635a-103">Big data architecture style</span></span>

<span data-ttu-id="d635a-104">Una arquitectura de macrodatos está diseñada para controlar la ingesta, el procesamiento y el análisis de datos que son demasiado grandes o complejos para los sistemas de bases de datos tradicionales.</span><span class="sxs-lookup"><span data-stu-id="d635a-104">A big data architecture is designed to handle the ingestion, processing, and analysis of data that is too large or complex for traditional database systems.</span></span>

![](./images/big-data-logical.svg)

 <span data-ttu-id="d635a-105">Las soluciones de macrodatos suelen implicar uno o varios de los tipos siguientes de cargas de trabajo:</span><span class="sxs-lookup"><span data-stu-id="d635a-105">Big data solutions typically involve one or more of the following types of workload:</span></span>

- <span data-ttu-id="d635a-106">Procesamiento por lotes de orígenes de macrodatos en reposo.</span><span class="sxs-lookup"><span data-stu-id="d635a-106">Batch processing of big data sources at rest.</span></span>
- <span data-ttu-id="d635a-107">Procesamiento en tiempo real de macrodatos en movimiento.</span><span class="sxs-lookup"><span data-stu-id="d635a-107">Real-time processing of big data in motion.</span></span>
- <span data-ttu-id="d635a-108">Exploración interactiva de macrodatos.</span><span class="sxs-lookup"><span data-stu-id="d635a-108">Interactive exploration of big data.</span></span>
- <span data-ttu-id="d635a-109">Análisis predictivo y aprendizaje automático.</span><span class="sxs-lookup"><span data-stu-id="d635a-109">Predictive analytics and machine learning.</span></span>

<span data-ttu-id="d635a-110">La mayoría de las arquitecturas de macrodatos incluyen algunos de los componentes siguientes (o todos ellos):</span><span class="sxs-lookup"><span data-stu-id="d635a-110">Most big data architectures include some or all of the following components:</span></span>

- <span data-ttu-id="d635a-111">**Orígenes de datos**: todas las soluciones de macrodatos se inician con uno o varios orígenes de datos.</span><span class="sxs-lookup"><span data-stu-id="d635a-111">**Data sources**: All big data solutions start with one or more data sources.</span></span> <span data-ttu-id="d635a-112">Algunos ejemplos son:</span><span class="sxs-lookup"><span data-stu-id="d635a-112">Examples include:</span></span>

    - <span data-ttu-id="d635a-113">Almacenes de datos de aplicación, como bases de datos relacionales.</span><span class="sxs-lookup"><span data-stu-id="d635a-113">Application data stores, such as relational databases.</span></span>
    - <span data-ttu-id="d635a-114">Archivos estáticos generados por aplicaciones, como archivos de registro de servidor web.</span><span class="sxs-lookup"><span data-stu-id="d635a-114">Static files produced by applications, such as web server log files.</span></span>
    - <span data-ttu-id="d635a-115">Orígenes de datos en tiempo real, como dispositivos de IoT.</span><span class="sxs-lookup"><span data-stu-id="d635a-115">Real-time data sources, such as IoT devices.</span></span>

- <span data-ttu-id="d635a-116">**Almacenamiento de datos**: los datos de las operaciones de procesamiento por lotes se almacenan normalmente en un almacén de archivos distribuido que puede contener importantes cantidades de archivos grandes en diferentes formatos.</span><span class="sxs-lookup"><span data-stu-id="d635a-116">**Data storage**: Data for batch processing operations is typically stored in a distributed file store that can hold high volumes of large files in various formats.</span></span> <span data-ttu-id="d635a-117">Este tipo de almacén se suele denominar *Data Lake*.</span><span class="sxs-lookup"><span data-stu-id="d635a-117">This kind of store is often called a *data lake*.</span></span> <span data-ttu-id="d635a-118">Las opciones para implementar este almacenamiento son Azure Data Lake Store o lo contenedores de blob en Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="d635a-118">Options for implementing this storage include Azure Data Lake Store or blob containers in Azure Storage.</span></span> 

- <span data-ttu-id="d635a-119">**Procesamiento por lotes**: como los conjuntos de datos son tan grandes, a menudo una solución de macrodatos debe procesar los archivos de datos mediante trabajos por lotes de ejecución prolongada para filtrar, agregar o bien preparar los datos para su análisis.</span><span class="sxs-lookup"><span data-stu-id="d635a-119">**Batch processing**: Because the data sets are so large, often a big data solution must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="d635a-120">Normalmente estos trabajos implican leer archivos de código fuente, procesarlos y escribir la salida en nuevos archivos.</span><span class="sxs-lookup"><span data-stu-id="d635a-120">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> <span data-ttu-id="d635a-121">Las opciones incluyen la ejecución de trabajos de U-SQL en Azure Data Lake Analytics, el uso de Hive, Pig o trabajos personalizados de Map/Reduce en un clúster de HDInsight Hadoop, o el uso de programas de Java, Scala o Python en un clúster de HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="d635a-121">Options include running U-SQL jobs in Azure Data Lake Analytics, using Hive, Pig, or custom Map/Reduce jobs in an HDInsight Hadoop cluster, or using Java, Scala, or Python programs in an HDInsight Spark cluster.</span></span>

- <span data-ttu-id="d635a-122">**Ingesta de mensajes en tiempo real**: si la solución incluye orígenes en tiempo real, la arquitectura debe incluir una manera de capturar y almacenar los mensajes en tiempo real para el procesamiento de secuencias.</span><span class="sxs-lookup"><span data-stu-id="d635a-122">**Real-time message ingestion**: If the solution includes real-time sources, the architecture must include a way to capture and store real-time messages for stream processing.</span></span> <span data-ttu-id="d635a-123">Podría tratarse de un sencillo almacén de datos, donde se colocan los mensajes entrantes en una carpeta para su procesamiento.</span><span class="sxs-lookup"><span data-stu-id="d635a-123">This might be a simple data store, where incoming messages are dropped into a folder for processing.</span></span> <span data-ttu-id="d635a-124">Sin embargo, muchas soluciones necesitan un almacén de ingesta de mensajes para que actúe como búfer de mensajes y para admitir el procesamiento de escalabilidad horizontal, la entrega confiable y otra semántica de puesta en cola de mensajes.</span><span class="sxs-lookup"><span data-stu-id="d635a-124">However, many solutions need a message ingestion store to act as a buffer for messages, and to support scale-out processing, reliable delivery, and other message queuing semantics.</span></span> <span data-ttu-id="d635a-125">Entre las opciones se encuentra Azure Event Hubs, Azure IoT Hubs y Kafka.</span><span class="sxs-lookup"><span data-stu-id="d635a-125">Options include Azure Event Hubs, Azure IoT Hubs, and Kafka.</span></span>

- <span data-ttu-id="d635a-126">**Procesamiento de flujos**: una vez capturados los mensajes en tiempo real, la solución debe procesarlos filtrando, agregando o bien preparando los datos para su análisis.</span><span class="sxs-lookup"><span data-stu-id="d635a-126">**Stream processing**: After capturing real-time messages, the solution must process them by filtering, aggregating, and otherwise preparing the data for analysis.</span></span> <span data-ttu-id="d635a-127">Los datos de secuencias procesados se escriben entonces en un receptor de salida.</span><span class="sxs-lookup"><span data-stu-id="d635a-127">The processed stream data is then written to an output sink.</span></span> <span data-ttu-id="d635a-128">Azure Stream Analytics proporciona un servicio de procesamiento de secuencias administrado basado en consultas SQL de ejecución permanente que operan en secuencias sin enlazar.</span><span class="sxs-lookup"><span data-stu-id="d635a-128">Azure Stream Analytics provides a managed stream processing service based on perpetually running SQL queries that operate on unbounded streams.</span></span> <span data-ttu-id="d635a-129">También puede utilizar tecnologías de streaming de código abierto como Storm y Spark Streaming en un clúster de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d635a-129">You can also use open source Apache streaming technologies like Storm and Spark Streaming in an HDInsight cluster.</span></span>

- <span data-ttu-id="d635a-130">**Almacén de datos analíticos**: muchas soluciones de macrodatos preparan los datos para el análisis y luego sirven los datos procesados en un formato estructurado que se puede consultar mediante herramientas de análisis.</span><span class="sxs-lookup"><span data-stu-id="d635a-130">**Analytical data store**: Many big data solutions prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> <span data-ttu-id="d635a-131">El almacén de datos analíticos que se utiliza para atender estas consultas puede ser un almacén de datos relacional de estilo Kimball, como se ve en la mayoría de soluciones tradicionales de inteligencia empresarial.</span><span class="sxs-lookup"><span data-stu-id="d635a-131">The analytical data store used to serve these queries can be a Kimball-style relational data warehouse, as seen in most traditional business intelligence (BI) solutions.</span></span> <span data-ttu-id="d635a-132">También es posible que los datos se presenten a través de una tecnología NoSQL de baja latencia como HBase, o una base de datos de Hive interactiva que proporciona una abstracción de metadatos sobre los archivos de datos en el almacén de datos distribuidos.</span><span class="sxs-lookup"><span data-stu-id="d635a-132">Alternatively, the data could be presented through a low-latency NoSQL technology such as HBase, or an interactive Hive database that provides a metadata abstraction over data files in the distributed data store.</span></span> <span data-ttu-id="d635a-133">Azure SQL Data Warehouse proporciona un servicio administrado para el almacenamiento de datos a gran escala basado en la nube.</span><span class="sxs-lookup"><span data-stu-id="d635a-133">Azure SQL Data Warehouse provides a managed service for large-scale, cloud-based data warehousing.</span></span> <span data-ttu-id="d635a-134">HDInsight admite Interactive Hive, HBase y Spark SQL, que también se puede utilizar para proporcionar datos par el análisis.</span><span class="sxs-lookup"><span data-stu-id="d635a-134">HDInsight supports Interactive Hive, HBase, and Spark SQL, which can also be used to serve data for analysis.</span></span>

- <span data-ttu-id="d635a-135">**Análisis y creación de informes**: el objetivo de la mayoría de soluciones de macrodatos consiste en proporcionar información sobre los datos a través de análisis e informes.</span><span class="sxs-lookup"><span data-stu-id="d635a-135">**Analysis and reporting**: The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> <span data-ttu-id="d635a-136">Para permitir que los usuarios analicen los datos, la arquitectura puede incluir una capa de modelado de datos, como un cubo OLAP multidimensional o un modelo de datos tabulares en Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="d635a-136">To empower users to analyze the data, the architecture may include a data modeling layer, such as a multidimensional OLAP cube or tabular data model in Azure Analysis Services.</span></span> <span data-ttu-id="d635a-137">También podría admitir inteligencia empresarial con características de autoservicio mediante las tecnologías de modelado y visualización en Microsoft Power BI o Microsoft Excel.</span><span class="sxs-lookup"><span data-stu-id="d635a-137">It might also support self-service BI, using the modeling and visualization technologies in Microsoft Power BI or Microsoft Excel.</span></span> <span data-ttu-id="d635a-138">Los análisis y la creación de informes también pueden adoptar la forma de exploración interactiva de datos por parte de científicos o analistas de datos.</span><span class="sxs-lookup"><span data-stu-id="d635a-138">Analysis and reporting can also take the form of interactive data exploration by data scientists or data analysts.</span></span> <span data-ttu-id="d635a-139">En estos casos, muchos servicios de Azure admiten bloc de notas analíticos, como Jupyter, lo cual permite a estos usuarios aprovechar sus conocimientos existentes con Python o R. En el caso de la exploración de datos a gran escala, puede utilizar Microsoft R Server, tanto de manera independiente como con Spark.</span><span class="sxs-lookup"><span data-stu-id="d635a-139">For these scenarios, many Azure services support analytical notebooks, such as Jupyter, enabling these users to leverage their existing skills with Python or R. For large-scale data exploration, you can use Microsoft R Server, either standalone or with Spark.</span></span>

- <span data-ttu-id="d635a-140">**Coordinación**: la mayoría de las soluciones de macrodatos constan de operaciones de procesamiento de datos repetidas, encapsuladas en flujos de trabajo, que transforman los datos de origen, mueven datos entre varios orígenes y receptores, cargan los datos procesados en un almacén de datos analítico o envían los resultados directamente a un informe o un panel.</span><span class="sxs-lookup"><span data-stu-id="d635a-140">**Orchestration**: Most big data solutions consist of repeated data processing operations, encapsulated in workflows, that transform source data, move data between multiple sources and sinks, load the processed data into an analytical data store, or push the results straight to a report or dashboard.</span></span> <span data-ttu-id="d635a-141">Para automatizar estos flujos de trabajo, puede utilizar una tecnología de coordinación como Azure Data Factory o Apache Oozie y Sqoop.</span><span class="sxs-lookup"><span data-stu-id="d635a-141">To automate these workflows, you can use an orchestration technology such Azure Data Factory or Apache Oozie and Sqoop.</span></span>

<span data-ttu-id="d635a-142">Azure incluye muchos servicios que se pueden usar en una arquitectura de macrodatos.</span><span class="sxs-lookup"><span data-stu-id="d635a-142">Azure includes many services that can be used in a big data architecture.</span></span> <span data-ttu-id="d635a-143">Se dividen aproximadamente en dos categorías:</span><span class="sxs-lookup"><span data-stu-id="d635a-143">They fall roughly into two categories:</span></span>

- <span data-ttu-id="d635a-144">Servicios administrados, como Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Azure Stream Analytics, Azure Event Hub, Azure IoT Hub y Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="d635a-144">Managed services, including Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Azure Stream Analytics, Azure Event Hub, Azure IoT Hub, and Azure Data Factory.</span></span>
- <span data-ttu-id="d635a-145">Tecnologías de código abierto basadas en la plataforma de Apache Hadoop, como HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop y Kafka.</span><span class="sxs-lookup"><span data-stu-id="d635a-145">Open source technologies based on the Apache Hadoop platform, including HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop, and Kafka.</span></span> <span data-ttu-id="d635a-146">Estas tecnologías están disponibles en Azure en el servicio Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="d635a-146">These technologies are available on Azure in the Azure HDInsight service.</span></span>

<span data-ttu-id="d635a-147">Estas opciones no son mutuamente excluyentes, y muchas soluciones combinan las tecnologías de código abierto con servicios de Azure.</span><span class="sxs-lookup"><span data-stu-id="d635a-147">These options are not mutually exclusive, and many solutions combine open source technologies with Azure services.</span></span>

## <a name="when-to-use-this-architecture"></a><span data-ttu-id="d635a-148">Cuándo utilizar esta arquitectura</span><span class="sxs-lookup"><span data-stu-id="d635a-148">When to use this architecture</span></span>

<span data-ttu-id="d635a-149">Considere este estilo de arquitectura cuando necesite:</span><span class="sxs-lookup"><span data-stu-id="d635a-149">Consider this architecture style when you need to:</span></span>

- <span data-ttu-id="d635a-150">Almacenar y procesar datos en volúmenes demasiado grandes para una base de datos tradicional.</span><span class="sxs-lookup"><span data-stu-id="d635a-150">Store and process data in volumes too large for a traditional database.</span></span>
- <span data-ttu-id="d635a-151">Transformar datos no estructurados para el análisis y la creación de informes.</span><span class="sxs-lookup"><span data-stu-id="d635a-151">Transform unstructured data for analysis and reporting.</span></span>
- <span data-ttu-id="d635a-152">Capturar, procesar y analizar flujos no asociados de datos en tiempo real, o con una latencia baja.</span><span class="sxs-lookup"><span data-stu-id="d635a-152">Capture, process, and analyze unbounded streams of data in real time, or with low latency.</span></span>
- <span data-ttu-id="d635a-153">Usar Azure Machine Learning o Microsoft Cognitive Services.</span><span class="sxs-lookup"><span data-stu-id="d635a-153">Use Azure Machine Learning or Microsoft Cognitive Services.</span></span>

## <a name="benefits"></a><span data-ttu-id="d635a-154">Ventajas</span><span class="sxs-lookup"><span data-stu-id="d635a-154">Benefits</span></span>

- <span data-ttu-id="d635a-155">**Opciones de tecnología**.</span><span class="sxs-lookup"><span data-stu-id="d635a-155">**Technology choices**.</span></span> <span data-ttu-id="d635a-156">Puede mezclar y combinar servicios administrados de Azure y tecnologías de Apache en clústeres de HDInsight, a fin de aprovechar los conocimientos existentes o las inversiones en tecnología.</span><span class="sxs-lookup"><span data-stu-id="d635a-156">You can mix and match Azure managed services and Apache technologies in HDInsight clusters, to capitalize on existing skills or technology investments.</span></span>
- <span data-ttu-id="d635a-157">**Rendimiento mediante paralelismo**.</span><span class="sxs-lookup"><span data-stu-id="d635a-157">**Performance through parallelism**.</span></span> <span data-ttu-id="d635a-158">Las soluciones de macrodatos aprovechan el paralelismo, habilitando soluciones de alto rendimiento que escalan a grandes volúmenes de datos.</span><span class="sxs-lookup"><span data-stu-id="d635a-158">Big data solutions take advantage of parallelism, enabling high-performance solutions that scale to large volumes of data.</span></span>
- <span data-ttu-id="d635a-159">**Escalado elástico**</span><span class="sxs-lookup"><span data-stu-id="d635a-159">**Elastic scale**.</span></span> <span data-ttu-id="d635a-160">Todos los componentes de la arquitectura de macrodatos admiten el aprovisionamiento de escalabilidad horizontal, de manera que puede ajustar la solución para cargas de trabajo pequeñas o grandes y pagar solo por los recursos que use.</span><span class="sxs-lookup"><span data-stu-id="d635a-160">All of the components in the big data architecture support scale-out provisioning, so that you can adjust your solution to small or large workloads, and pay only for the resources that you use.</span></span>
- <span data-ttu-id="d635a-161">**Interoperabilidad con soluciones existentes**.</span><span class="sxs-lookup"><span data-stu-id="d635a-161">**Interoperability with existing solutions**.</span></span> <span data-ttu-id="d635a-162">Los componentes de la arquitectura de macrodatos también se usan para el procesamiento de IoT y las soluciones de inteligencia empresarial en las compañías, lo que le permite crear una solución integrada entre las cargas de trabajo de datos.</span><span class="sxs-lookup"><span data-stu-id="d635a-162">The components of the big data architecture are also used for IoT processing and enterprise BI solutions, enabling you to create an integrated solution across data workloads.</span></span>

## <a name="challenges"></a><span data-ttu-id="d635a-163">Desafíos</span><span class="sxs-lookup"><span data-stu-id="d635a-163">Challenges</span></span>

- <span data-ttu-id="d635a-164">**Complejidad**.</span><span class="sxs-lookup"><span data-stu-id="d635a-164">**Complexity**.</span></span> <span data-ttu-id="d635a-165">Las soluciones de macrodatos pueden ser muy complejas, con numerosos componentes para controlar la ingesta de datos procedentes de varios orígenes de datos.</span><span class="sxs-lookup"><span data-stu-id="d635a-165">Big data solutions can be extremely complex, with numerous components to handle data ingestion from multiple data sources.</span></span> <span data-ttu-id="d635a-166">Puede resultar complicado compilar, probar y solucionar problemas derivados de los procesos de macrodatos.</span><span class="sxs-lookup"><span data-stu-id="d635a-166">It can be challenging to build, test, and troubleshoot big data processes.</span></span> <span data-ttu-id="d635a-167">Además, puede haber un gran número de valores de configuración entre varios sistemas que se deben utilizar con el fin de optimizar el rendimiento.</span><span class="sxs-lookup"><span data-stu-id="d635a-167">Moreover, there may be a large number of configuration settings across multiple systems that must be used in order to optimize performance.</span></span>
- <span data-ttu-id="d635a-168">**Conjunto de habilidades**.</span><span class="sxs-lookup"><span data-stu-id="d635a-168">**Skillset**.</span></span> <span data-ttu-id="d635a-169">Muchas tecnologías de macrodatos están muy especializadas y usan marcos de trabajo y lenguajes que no son habituales en arquitecturas de aplicación más generales.</span><span class="sxs-lookup"><span data-stu-id="d635a-169">Many big data technologies are highly specialized, and use frameworks and languages that are not typical of more general application architectures.</span></span> <span data-ttu-id="d635a-170">Por otro lado, las tecnologías de macrodatos están desarrollando nuevas API que se basan en lenguajes más establecidos.</span><span class="sxs-lookup"><span data-stu-id="d635a-170">On the other hand, big data technologies are evolving new APIs that build on more established languages.</span></span> <span data-ttu-id="d635a-171">Por ejemplo, el lenguaje U-SQL de Azure Data Lake Analytics se basa en una combinación de Transact-SQL y C#.</span><span class="sxs-lookup"><span data-stu-id="d635a-171">For example, the U-SQL language in Azure Data Lake Analytics is based on a combination of Transact-SQL and C#.</span></span> <span data-ttu-id="d635a-172">De forma similar, las API basadas en SQL están disponibles para Hive, HBase y Spark.</span><span class="sxs-lookup"><span data-stu-id="d635a-172">Similarly, SQL-based APIs are available for Hive, HBase, and Spark.</span></span>
- <span data-ttu-id="d635a-173">**Consolidación tecnológica**.</span><span class="sxs-lookup"><span data-stu-id="d635a-173">**Technology maturity**.</span></span> <span data-ttu-id="d635a-174">Muchas de las tecnologías utilizadas en macrodatos están evolucionando.</span><span class="sxs-lookup"><span data-stu-id="d635a-174">Many of the technologies used in big data are evolving.</span></span> <span data-ttu-id="d635a-175">Mientras que tecnologías básicas de Hadoop como Hive y Pig se han estabilizado, las nuevas tecnologías como Spark introducen amplios cambios y mejoras con cada nueva versión.</span><span class="sxs-lookup"><span data-stu-id="d635a-175">While core Hadoop technologies such as Hive and Pig have stabilized, emerging technologies such as Spark introduce extensive changes and enhancements with each new release.</span></span> <span data-ttu-id="d635a-176">Los servicios administrados como Azure Data Lake Analytics y Azure Data Factory son relativamente jóvenes en comparación con otros servicios de Azure, y probablemente evolucionarán con el tiempo.</span><span class="sxs-lookup"><span data-stu-id="d635a-176">Managed services such as Azure Data Lake Analytics and Azure Data Factory are relatively young, compared with other Azure services, and will likely evolve over time.</span></span>
- <span data-ttu-id="d635a-177">**Seguridad**.</span><span class="sxs-lookup"><span data-stu-id="d635a-177">**Security**.</span></span> <span data-ttu-id="d635a-178">Las soluciones de macrodatos normalmente dependen del almacenamiento de todos los datos estáticos en una instancia de Data Lake centralizada.</span><span class="sxs-lookup"><span data-stu-id="d635a-178">Big data solutions usually rely on storing all static data in a centralized data lake.</span></span> <span data-ttu-id="d635a-179">La protección del acceso a estos datos puede ser complicada, especialmente cuando los datos deben ser recibidos y utilizados por varias aplicaciones y plataformas.</span><span class="sxs-lookup"><span data-stu-id="d635a-179">Securing access to this data can be challenging, especially when the data must be ingested and consumed by multiple applications and platforms.</span></span>

## <a name="best-practices"></a><span data-ttu-id="d635a-180">Prácticas recomendadas</span><span class="sxs-lookup"><span data-stu-id="d635a-180">Best practices</span></span>

- <span data-ttu-id="d635a-181">**Aproveche el paralelismo**.</span><span class="sxs-lookup"><span data-stu-id="d635a-181">**Leverage parallelism**.</span></span> <span data-ttu-id="d635a-182">Las tecnologías de procesamiento de macrodatos distribuyen la carga de trabajo entre varias unidades de procesamiento.</span><span class="sxs-lookup"><span data-stu-id="d635a-182">Most big data processing technologies distribute the workload across multiple processing units.</span></span> <span data-ttu-id="d635a-183">Esto requiere que los archivos de datos estáticos se creen y almacenen en un formato divisible.</span><span class="sxs-lookup"><span data-stu-id="d635a-183">This requires that static data files are created and stored in a splittable format.</span></span> <span data-ttu-id="d635a-184">Los sistemas de archivos distribuidos, como HDFS, pueden optimizar el rendimiento de lectura y escritura, y el procesamiento real se lleva a cabo por varios nodos de clúster en paralelo, lo cual reduce los tiempos de trabajo global.</span><span class="sxs-lookup"><span data-stu-id="d635a-184">Distributed file systems such as HDFS can optimize read and write performance, and the actual processing is performed by multiple cluster nodes in parallel, which reduces overall job times.</span></span>

- <span data-ttu-id="d635a-185">**Cree particiones de datos**.</span><span class="sxs-lookup"><span data-stu-id="d635a-185">**Partition data**.</span></span> <span data-ttu-id="d635a-186">El procesamiento por lotes normalmente tiene lugar según una programación periódica; por ejemplo, semanal o mensualmente.</span><span class="sxs-lookup"><span data-stu-id="d635a-186">Batch processing usually happens on a recurring schedule &mdash; for example, weekly or monthly.</span></span> <span data-ttu-id="d635a-187">Cree particiones de archivos de datos y estructuras de datos, como tablas, en función de periodos temporales que coinciden con la programación del procesamiento.</span><span class="sxs-lookup"><span data-stu-id="d635a-187">Partition data files, and data structures such as tables, based on temporal periods that match the processing schedule.</span></span> <span data-ttu-id="d635a-188">Con esto se simplifica la programación de trabajos y la ingesta de datos y se facilita la solución de problemas.</span><span class="sxs-lookup"><span data-stu-id="d635a-188">That simplifies data ingestion and job scheduling, and makes it easier to troubleshoot failures.</span></span> <span data-ttu-id="d635a-189">Ademas, la creación de particiones en tablas que se usan en consultas de Hive, U-SQL o SQL pueden mejorar sustancialmente el rendimiento de las consultas.</span><span class="sxs-lookup"><span data-stu-id="d635a-189">Also, partitioning tables that are used in Hive, U-SQL, or SQL queries can significantly improve query performance.</span></span>

- <span data-ttu-id="d635a-190">**Aplique la semántica de esquema en lectura**.</span><span class="sxs-lookup"><span data-stu-id="d635a-190">**Apply schema-on-read semantics**.</span></span> <span data-ttu-id="d635a-191">El uso de una instancia de Data Lake permite combinar el almacenamiento de archivos en varios formatos, ya sea estructurados, semiestructurados o no estructurados.</span><span class="sxs-lookup"><span data-stu-id="d635a-191">Using a data lake lets you to combine storage for files in multiple formats, whether structured, semi-structured, or unstructured.</span></span> <span data-ttu-id="d635a-192">Use la semántica de *esquema en lectura*, que proyecta un esquema en los datos cuando estos se procesan, no cuando se almacenan.</span><span class="sxs-lookup"><span data-stu-id="d635a-192">Use *schema-on-read* semantics, which project a schema onto the data when the data is processing, not when the data is stored.</span></span> <span data-ttu-id="d635a-193">Esto agrega flexibilidad a la solución y evita los cuellos de botella durante la ingesta de datos causados por la validación de datos y la comprobación de tipos.</span><span class="sxs-lookup"><span data-stu-id="d635a-193">This builds flexibility into the solution, and prevents bottlenecks during data ingestion caused by data validation and type checking.</span></span>

- <span data-ttu-id="d635a-194">**Procese los datos in situ**.</span><span class="sxs-lookup"><span data-stu-id="d635a-194">**Process data in-place**.</span></span> <span data-ttu-id="d635a-195">Las soluciones tradicionales de inteligencia empresarial suelen usar un proceso de extracción, transformación y carga para mover datos a un almacén de datos.</span><span class="sxs-lookup"><span data-stu-id="d635a-195">Traditional BI solutions often use an extract, transform, and load (ETL) process to move data into a data warehouse.</span></span> <span data-ttu-id="d635a-196">Con datos de volúmenes más grandes y una gran variedad de formatos, las soluciones de macrodatos normalmente usan variaciones del proceso de extracción, transformación y carga; por ejemplo, cambiando el orden a transformación, extracción y carga.</span><span class="sxs-lookup"><span data-stu-id="d635a-196">With larger volumes data, and a greater variety of formats, big data solutions generally use variations of ETL, such as transform, extract, and load (TEL).</span></span> <span data-ttu-id="d635a-197">Con este planteamiento, los datos se procesan en el almacén de datos distribuidos, transformándolos a la estructura necesaria, antes de mover los datos transformados a un almacén de datos analíticos.</span><span class="sxs-lookup"><span data-stu-id="d635a-197">With this approach, the data is processed within the distributed data store, transforming it to the required structure, before moving the transformed data into an analytical data store.</span></span>

- <span data-ttu-id="d635a-198">**Equilibre los costes de uso y tiempo**.</span><span class="sxs-lookup"><span data-stu-id="d635a-198">**Balance utilization and time costs**.</span></span> <span data-ttu-id="d635a-199">En el caso de los trabajos de procesamiento por lotes, es importante tener en cuenta dos factores: el costo por unidad de los nodos de proceso y el costo por minuto del uso de esos nodos para completar el trabajo.</span><span class="sxs-lookup"><span data-stu-id="d635a-199">For batch processing jobs, it's important to consider two factors: The per-unit cost of the compute nodes, and the per-minute cost of using those nodes to complete the job.</span></span> <span data-ttu-id="d635a-200">Por ejemplo, un trabajo por lotes puede tardar ocho horas con cuatro nodos de clúster.</span><span class="sxs-lookup"><span data-stu-id="d635a-200">For example, a batch job may take eight hours with four cluster nodes.</span></span> <span data-ttu-id="d635a-201">Sin embargo, podría ocurrir que el trabajo utilice los cuatro nodos solo durante las dos primeras horas y, después, solo fueran necesarios dos nodos.</span><span class="sxs-lookup"><span data-stu-id="d635a-201">However, it might turn out that the job uses all four nodes only during the first two hours, and after that, only two nodes are required.</span></span> <span data-ttu-id="d635a-202">En ese caso, la ejecución de todo el trabajo en dos nodos podría aumentar el tiempo total del trabajo, pero no lo duplicaría, por lo que el coste total sería menor.</span><span class="sxs-lookup"><span data-stu-id="d635a-202">In that case, running the entire job on two nodes would increase the total job time, but would not double it, so the total cost would be less.</span></span> <span data-ttu-id="d635a-203">En algunos escenarios empresariales, un mayor tiempo de procesamiento puede ser preferible al mayor costo de contar con recursos de clúster infrautilizados</span><span class="sxs-lookup"><span data-stu-id="d635a-203">In some business scenarios, a longer processing time may be preferable to the higher cost of using under-utilized cluster resources.</span></span>

- <span data-ttu-id="d635a-204">**Separe los recursos de clúster**.</span><span class="sxs-lookup"><span data-stu-id="d635a-204">**Separate cluster resources**.</span></span> <span data-ttu-id="d635a-205">Al implementar clústeres de HDInsight, normalmente conseguirá un mejor rendimiento mediante el aprovisionamiento de recursos de clúster por separado para cada tipo de carga de trabajo.</span><span class="sxs-lookup"><span data-stu-id="d635a-205">When deploying HDInsight clusters, you will normally achieve better performance by provisioning separate cluster resources for each type of workload.</span></span> <span data-ttu-id="d635a-206">Por ejemplo, aunque los clústeres de Spark incluyen Hive, si necesita realizar procesamientos exhaustivos con Hive y Spark, probablemente le convenga implementar clústeres de Spark y Hadoop dedicados de manera independiente.</span><span class="sxs-lookup"><span data-stu-id="d635a-206">For example, although Spark clusters include Hive, if you need to perform extensive processing with both Hive and Spark, you should consider deploying separate dedicated Spark and Hadoop clusters.</span></span> <span data-ttu-id="d635a-207">De forma similar, si usa HBase y Storm para el procesamiento de secuencias de baja latencia y también Hive para el procesamiento por lotes, considere la posibilidad de disponer de clústeres independientes para Storm, HBase y Hadoop.</span><span class="sxs-lookup"><span data-stu-id="d635a-207">Similarly, if you are using HBase and Storm for low latency stream processing and Hive for batch processing, consider separate clusters for Storm, HBase, and Hadoop.</span></span>

- <span data-ttu-id="d635a-208">**Coordine la ingesta de datos**.</span><span class="sxs-lookup"><span data-stu-id="d635a-208">**Orchestrate data ingestion**.</span></span> <span data-ttu-id="d635a-209">En algunos casos, las aplicaciones empresariales existentes pueden escribir archivos de datos para el procesamiento por lotes directamente en los contenedores de blobs de Azure Storage, donde los pueden utilizar HDInsight o Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="d635a-209">In some cases, existing business applications may write data files for batch processing directly into Azure storage blob containers, where they can be consumed by HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="d635a-210">Sin embargo, a menudo necesitará coordinar la ingesta de datos desde orígenes de datos externos o locales en la instancia de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="d635a-210">However, you will often need to orchestrate the ingestion of data from on-premises or external data sources into the data lake.</span></span> <span data-ttu-id="d635a-211">Utilice un flujo de trabajo o una canalización de coordinación, como los que admite Azure Data Factory o bien Oozie, a fin de lograr esto de forma predecible y fácil de administrar centralmente.</span><span class="sxs-lookup"><span data-stu-id="d635a-211">Use an orchestration workflow or pipeline, such as those supported by Azure Data Factory or Oozie, to achieve this in a predictable and centrally manageable fashion.</span></span>

- <span data-ttu-id="d635a-212">**Omita los datos confidenciales al principio**.</span><span class="sxs-lookup"><span data-stu-id="d635a-212">**Scrub sensitive data early**.</span></span> <span data-ttu-id="d635a-213">El flujo de trabajo de la ingesta de datos debería omitir los datos confidenciales al principio del proceso a fin de evitar su almacenamiento en la instancia de Data Lake.</span><span class="sxs-lookup"><span data-stu-id="d635a-213">The data ingestion workflow should scrub sensitive data early in the process, to avoid storing it in the data lake.</span></span>
