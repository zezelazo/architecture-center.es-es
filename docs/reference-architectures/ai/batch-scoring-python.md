---
title: Puntuación por lotes de modelos de Python en Azure
description: Cree una solución escalable para los modelos de puntuación por lotes en una programación en paralelo mediante Azure Batch AI.
author: njray
ms.date: 12/13/18
ms.custom: azcat-ai
ms.openlocfilehash: 93fc0c81663931c0a8b0f54b41934287056e6953
ms.sourcegitcommit: fb22348f917a76e30a6c090fcd4a18decba0b398
ms.translationtype: HT
ms.contentlocale: es-ES
ms.lasthandoff: 12/16/2018
ms.locfileid: "53450839"
---
# <a name="batch-scoring-of-python-models-on-azure"></a><span data-ttu-id="068b3-103">Puntuación por lotes de modelos de Python en Azure</span><span class="sxs-lookup"><span data-stu-id="068b3-103">Batch scoring of Python models on Azure</span></span>

<span data-ttu-id="068b3-104">Esta arquitectura de referencia muestra cómo crear una solución escalable para la puntuación por lotes de muchos modelos de una programación en paralelo mediante Azure Batch AI.</span><span class="sxs-lookup"><span data-stu-id="068b3-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Batch AI.</span></span> <span data-ttu-id="068b3-105">La solución se puede usar como plantilla y se puede generalizar para diferentes problemas.</span><span class="sxs-lookup"><span data-stu-id="068b3-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="068b3-106">En  [GitHub][github] hay disponible una implementación de referencia de esta arquitectura.</span><span class="sxs-lookup"><span data-stu-id="068b3-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Puntuación por lotes de modelos de Python en Azure](./_images/batch-scoring-python.png)

<span data-ttu-id="068b3-108">**Escenario**: Esta solución supervisa el funcionamiento de un gran número de dispositivos en una configuración de IoT en la que cada dispositivo envía lecturas de sensor continuamente.</span><span class="sxs-lookup"><span data-stu-id="068b3-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="068b3-109">Se supone que cada dispositivo tiene modelos de detección de anomalías entrenados previamente que se deben usar para predecir si una serie de medidas, que se agregan a través de un intervalo predefinido, corresponde a una anomalía, o no.</span><span class="sxs-lookup"><span data-stu-id="068b3-109">Each device is assumed to have pre-trained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="068b3-110">En escenarios del mundo real, podría tratarse de una secuencia de lecturas de los sensores que se deben filtrar y agregar antes de utilizarse en el entrenamiento o la puntuación en tiempo real.</span><span class="sxs-lookup"><span data-stu-id="068b3-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="068b3-111">Por motivos de simplicidad, la solución utiliza el mismo archivo de datos al ejecutar trabajos de puntuación.</span><span class="sxs-lookup"><span data-stu-id="068b3-111">For simplicity, the solution uses the same data file when executing scoring jobs.</span></span>

## <a name="architecture"></a><span data-ttu-id="068b3-112">Arquitectura</span><span class="sxs-lookup"><span data-stu-id="068b3-112">Architecture</span></span>

<span data-ttu-id="068b3-113">Esta arquitectura consta de los siguientes componentes:</span><span class="sxs-lookup"><span data-stu-id="068b3-113">This architecture consists of the following components:</span></span>

<span data-ttu-id="068b3-114">[Azure Event Hubs][event-hubs].</span><span class="sxs-lookup"><span data-stu-id="068b3-114">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="068b3-115">Este servicio de ingesta de mensajes puede ingerir millones de mensajes de eventos por segundo.</span><span class="sxs-lookup"><span data-stu-id="068b3-115">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="068b3-116">En esta arquitectura, los sensores envían un flujo de datos al centro de eventos.</span><span class="sxs-lookup"><span data-stu-id="068b3-116">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="068b3-117">[Azure Stream Analytics][stream-analytics].</span><span class="sxs-lookup"><span data-stu-id="068b3-117">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="068b3-118">Un motor de procesamiento de eventos.</span><span class="sxs-lookup"><span data-stu-id="068b3-118">An event-processing engine.</span></span> <span data-ttu-id="068b3-119">Un trabajo de Stream Analytics lee los flujos de datos del centro de eventos y realiza su procesamiento.</span><span class="sxs-lookup"><span data-stu-id="068b3-119">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="068b3-120">[Azure Batch AI][batch-ai].</span><span class="sxs-lookup"><span data-stu-id="068b3-120">[Azure Batch AI][batch-ai].</span></span> <span data-ttu-id="068b3-121">Este motor de computación distribuida se usa para entrenar y probar los modelos de aprendizaje automático e inteligencia artificial a escala en Azure.</span><span class="sxs-lookup"><span data-stu-id="068b3-121">This distributed computing engine is used to train and test machine learning and AI models at scale in Azure.</span></span> <span data-ttu-id="068b3-122">Batch AI crea máquinas virtuales a petición con una opción de escalado automático, donde cada nodo del clúster de Batch AI ejecuta un trabajo de puntuación para un sensor concreto.</span><span class="sxs-lookup"><span data-stu-id="068b3-122">Batch AI creates virtual machines on demand with an automatic scaling option, where each node in the Batch AI cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="068b3-123">El [script][python-script] de puntuación en Python se ejecuta en contenedores de Docker que se crean en cada nodo del clúster, donde lee los datos de los sensores pertinentes, genera predicciones y las almacena en el almacenamiento de blobs.</span><span class="sxs-lookup"><span data-stu-id="068b3-123">The scoring Python [script][python-script] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

<span data-ttu-id="068b3-124">[Azure Blob Storage][storage].</span><span class="sxs-lookup"><span data-stu-id="068b3-124">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="068b3-125">Los contenedores de blobs se usan para almacenar los modelos previamente entrenados, los datos y las predicciones de salida.</span><span class="sxs-lookup"><span data-stu-id="068b3-125">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="068b3-126">Los modelos se cargan en el almacenamiento de blobs en el cuaderno [create\_resources.ipynb][create-resources].</span><span class="sxs-lookup"><span data-stu-id="068b3-126">The models are uploaded to Blob storage in the [create\_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="068b3-127">Estos modelos de [SVM de una sola clase][one-class-svm] están entrenados en datos que representan los valores de los diferentes sensores de distintos dispositivos.</span><span class="sxs-lookup"><span data-stu-id="068b3-127">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="068b3-128">En esta solución se da por supuesto que los valores de los datos se agregan en un intervalo fijo.</span><span class="sxs-lookup"><span data-stu-id="068b3-128">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="068b3-129">[Azure Logic Apps][logic-apps].</span><span class="sxs-lookup"><span data-stu-id="068b3-129">[Azure Logic Apps][logic-apps].</span></span> <span data-ttu-id="068b3-130">Esta solución crea una aplicación lógica que se ejecuta trabajos de Batch AI cada hora.</span><span class="sxs-lookup"><span data-stu-id="068b3-130">This solution creates a Logic App that runs hourly Batch AI jobs.</span></span> <span data-ttu-id="068b3-131">Logic Apps proporciona una forma fácil de crear el flujo de trabajo del runtime y la programación de la solución.</span><span class="sxs-lookup"><span data-stu-id="068b3-131">Logic Apps provides an easy way to create the runtime workflow and scheduling for the solution.</span></span> <span data-ttu-id="068b3-132">Los trabajos de Batch AI se envían mediante un [script][script] de Python que también se ejecuta en un contenedor de Docker.</span><span class="sxs-lookup"><span data-stu-id="068b3-132">The Batch AI jobs are submitted using a Python [script][script] that also runs in a Docker container.</span></span>

<span data-ttu-id="068b3-133">[Azure Container Registry][acr].</span><span class="sxs-lookup"><span data-stu-id="068b3-133">[Azure Container Registry][acr].</span></span> <span data-ttu-id="068b3-134">Las imágenes de Docker se usan tanto en Batch AI como en Logic Apps, se crean en el cuaderno [create\_resources.ipynb][create-resources] y luego se insertan en Container Registry.</span><span class="sxs-lookup"><span data-stu-id="068b3-134">Docker images are used in both Batch AI and Logic Apps and are created in the [create\_resources.ipynb][create-resources] notebook, then pushed to Container Registry.</span></span> <span data-ttu-id="068b3-135">Esto proporciona una forma cómoda de hospedar imágenes y crear instancias de contenedores a través de otros servicios de Azure (Logic Apps y Batch AI en esta solución).</span><span class="sxs-lookup"><span data-stu-id="068b3-135">This provides a convenient way to host images and instantiate containers through other Azure services—Logic Apps and Batch AI in this solution.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="068b3-136">Consideraciones sobre rendimiento</span><span class="sxs-lookup"><span data-stu-id="068b3-136">Performance considerations</span></span>

<span data-ttu-id="068b3-137">En los modelos de Python estándar, se suele aceptar que las CPU son suficientes para controlar la carga de trabajo.</span><span class="sxs-lookup"><span data-stu-id="068b3-137">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="068b3-138">Esta arquitectura utiliza varias CPU.</span><span class="sxs-lookup"><span data-stu-id="068b3-138">This architecture uses CPUs.</span></span> <span data-ttu-id="068b3-139">Sin embargo, para [cargas de trabajo de aprendizaje profundo][deep], el rendimiento de las GPU normalmente es muy superior al de las CPU (en la medida en que un clúster del tamaño de las CPU suele ser necesario para obtener un rendimiento comparable).</span><span class="sxs-lookup"><span data-stu-id="068b3-139">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount—a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-vs-cores"></a><span data-ttu-id="068b3-140">Poner en paralelo las máquinas virtuales con los núcleos</span><span class="sxs-lookup"><span data-stu-id="068b3-140">Parallelizing across VMs vs cores</span></span>

<span data-ttu-id="068b3-141">Al ejecutar los procesos de puntuación de muchos modelos de puntuación en modo por lotes, es preciso que los trabajos se ejecuten en paralelo en las máquinas virtuales.</span><span class="sxs-lookup"><span data-stu-id="068b3-141">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="068b3-142">Hay dos enfoques posibles:</span><span class="sxs-lookup"><span data-stu-id="068b3-142">Two approaches are possible:</span></span> 

* <span data-ttu-id="068b3-143">Crear un clúster mayor mediante máquinas virtuales de bajo costo.</span><span class="sxs-lookup"><span data-stu-id="068b3-143">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="068b3-144">Crear un clúster menor mediante máquinas virtuales de alto rendimiento con más núcleos disponibles en cada una de ellas.</span><span class="sxs-lookup"><span data-stu-id="068b3-144">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="068b3-145">En general, la puntuación de los modelos de Python estándar no es tan exigente como la de los de aprendizaje profundo y un clúster pequeño debería poder controlar de forma eficaz un gran número de modelos en cola.</span><span class="sxs-lookup"><span data-stu-id="068b3-145">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="068b3-146">Puede aumentar el número de nodos de clúster a medida que aumenten los tamaños de los conjunto de datos.</span><span class="sxs-lookup"><span data-stu-id="068b3-146">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="068b3-147">Por comodidad en este escenario, se envía una tarea de puntuación dentro de un trabajo de Batch AI individual.</span><span class="sxs-lookup"><span data-stu-id="068b3-147">For convenience in this scenario, one scoring task is submitted within a single Batch AI job.</span></span> <span data-ttu-id="068b3-148">Sin embargo, es posible que sea más eficaz puntuar varios fragmentos de datos dentro del mismo trabajo de Batch AI.</span><span class="sxs-lookup"><span data-stu-id="068b3-148">However, it can be more efficient to score multiple data chunks within the same Batch AI job.</span></span> <span data-ttu-id="068b3-149">En esos casos, escriba código personalizado para leer en varios conjuntos de datos y ejecutar el script de puntuación para aquellos durante la ejecución de un único trabajo de Batch AI.</span><span class="sxs-lookup"><span data-stu-id="068b3-149">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single Batch AI job execution.</span></span>

### <a name="file-servers"></a><span data-ttu-id="068b3-150">Servidores de archivos</span><span class="sxs-lookup"><span data-stu-id="068b3-150">File servers</span></span>

<span data-ttu-id="068b3-151">Al usar Batch AI, puede elegir varias opciones de almacenamiento según el rendimiento necesario para el escenario.</span><span class="sxs-lookup"><span data-stu-id="068b3-151">When using Batch AI, you can choose multiple storage options depending on the throughput needed for your scenario.</span></span> <span data-ttu-id="068b3-152">Para cargas de trabajo con requisitos de rendimiento bajo, debe ser suficiente con Blob Storage.</span><span class="sxs-lookup"><span data-stu-id="068b3-152">For workloads with low throughput requirements, using blob storage should be enough.</span></span> <span data-ttu-id="068b3-153">De forma alternativa, Batch AI también admite un [servidor de archivos de Batch AI][bai-file-server], un NFS administrado de un solo nodo que se puede montar automáticamente en los nodos del clúster para proporcionar una ubicación de almacenamiento accesible centralmente para los trabajos.</span><span class="sxs-lookup"><span data-stu-id="068b3-153">Alternatively, Batch AI also supports a [Batch AI File Server][bai-file-server], a managed, single-node NFS, which can be automatically mounted on cluster nodes to provide a centrally accessible storage location for jobs.</span></span> <span data-ttu-id="068b3-154">Para la mayoría de los casos, se necesita un solo servidor de archivos en un área de trabajo y se pueden separar los datos para los trabajos de aprendizaje en directorios distintos.</span><span class="sxs-lookup"><span data-stu-id="068b3-154">For most cases, only one file server is needed in a workspace, and you can separate data for your training jobs into different directories.</span></span>

<span data-ttu-id="068b3-155">Si un NFS de un solo nodo no es adecuado para las cargas de trabajo, Batch AI admite otras opciones de almacenamiento, como [Azure Files][azure-files], y soluciones personalizadas, como un sistema de archivos Gluster o Lustre.</span><span class="sxs-lookup"><span data-stu-id="068b3-155">If a single-node NFS isn't appropriate for your workloads, Batch AI supports other storage options, including [Azure Files][azure-files] and custom solutions such as a Gluster or Lustre file system.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="068b3-156">Consideraciones de administración</span><span class="sxs-lookup"><span data-stu-id="068b3-156">Management considerations</span></span>

### <a name="monitoring-batch-ai-jobs"></a><span data-ttu-id="068b3-157">Supervisión de trabajos de Batch AI</span><span class="sxs-lookup"><span data-stu-id="068b3-157">Monitoring Batch AI jobs</span></span>

<span data-ttu-id="068b3-158">Es importante supervisar el progreso de los trabajos en ejecución, pero puede ser un desafío hacerlo en un clúster de nodos activos.</span><span class="sxs-lookup"><span data-stu-id="068b3-158">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="068b3-159">Para obtener una idea del estado general del clúster, vaya a la hoja **Batch AI** de [Azure Portal][portal] para inspeccionar el estado de los nodos del clúster.</span><span class="sxs-lookup"><span data-stu-id="068b3-159">To get a sense of the overall state of the cluster, go to the **Batch AI** blade of the [Azure Portal][portal] to inspect the state of the nodes in the cluster.</span></span> <span data-ttu-id="068b3-160">Si algún nodo está inactivo o se produce un error en algún trabajo, los registros de errores se guardan en Blob Storage, pero también se puede acceder a ellos desde la hoja **Trabajos** del portal.</span><span class="sxs-lookup"><span data-stu-id="068b3-160">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the **Jobs** blade of the portal.</span></span>

<span data-ttu-id="068b3-161">Para que la supervisión sea más exhaustiva, conecte los registros a [Application Insights][ai] o ejecute procesos independientes para sondear el estado del clúster de Batch AI y sus trabajos.</span><span class="sxs-lookup"><span data-stu-id="068b3-161">For richer monitoring, connect logs to [Application Insights][ai], or run separate processes to poll for the state of the Batch AI cluster and its jobs.</span></span>

### <a name="logging-in-batch-ai"></a><span data-ttu-id="068b3-162">Registros en Batch AI</span><span class="sxs-lookup"><span data-stu-id="068b3-162">Logging in Batch AI</span></span>

<span data-ttu-id="068b3-163">Batch AI registra todos los stdout/stderr en la cuenta de Azure Storage asociada.</span><span class="sxs-lookup"><span data-stu-id="068b3-163">Batch AI logs all stdout/stderr to the associated Azure storage account.</span></span> <span data-ttu-id="068b3-164">Para facilitar la navegación en los archivos de registro, use una herramienta de exploración de almacenamiento como [Explorador de Azure Storage][explorer].</span><span class="sxs-lookup"><span data-stu-id="068b3-164">For easy navigation of the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

<span data-ttu-id="068b3-165">Al implementar esta arquitectura de referencia, tiene la opción de configurar un sistema de registro más sencillo.</span><span class="sxs-lookup"><span data-stu-id="068b3-165">When you deploy this reference architecture, you have the option to set up a simpler logging system.</span></span> <span data-ttu-id="068b3-166">Con esta opción, todos los registros de los distintos trabajos que se guardan en el mismo directorio del contenedor de blobs, como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="068b3-166">With this option, all the logs across the different jobs are saved to the same directory in your blob container as shown below.</span></span> <span data-ttu-id="068b3-167">Use dichos registros para supervisar el tiempo que tardan en procesarse casa trabajo y cada imagen, con el fin de que sepa mejor cómo optimizar el proceso.</span><span class="sxs-lookup"><span data-stu-id="068b3-167">Use these logs to monitor how long it takes for each job and each image to process, so you have a better sense of how to optimize the process.</span></span>

![Explorador de Azure Storage](./_images/batch-scoring-python-monitor.png)

## <a name="cost-considerations"></a><span data-ttu-id="068b3-169">Consideraciones sobre el costo</span><span class="sxs-lookup"><span data-stu-id="068b3-169">Cost considerations</span></span>

<span data-ttu-id="068b3-170">Los componentes más caros que se usan en esta arquitectura de referencia son los recursos de proceso.</span><span class="sxs-lookup"><span data-stu-id="068b3-170">The most expensive components used in this reference architecture are the compute resources.</span></span>

<span data-ttu-id="068b3-171">El tamaño del clúster de Batch AI se escala y se reduce verticalmente en función de los trabajos que haya en la cola.</span><span class="sxs-lookup"><span data-stu-id="068b3-171">The Batch AI cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="068b3-172">El [escalado automático][automatic-scaling] se puede habilitar con Batch AI de una de las dos formas siguientes.</span><span class="sxs-lookup"><span data-stu-id="068b3-172">You can enable [automatic scaling][automatic-scaling] with Batch AI in one of two ways.</span></span> <span data-ttu-id="068b3-173">Se puede hacer mediante programación, lo que se puede configurar en el archivo .env que forma parte de los [pasos de implementación][github], o bien se puede cambiar la fórmula de escalado directamente en el portal después de crear el clúster.</span><span class="sxs-lookup"><span data-stu-id="068b3-173">You can do so programmatically, which can be configured in the .env file that is part of the [deployment steps][github], or you can change the scale formula directly in the portal after the cluster is created.</span></span>

<span data-ttu-id="068b3-174">Para el trabajo que no requiera un procesamiento inmediato, configure la fórmula de escalado automático, con el fin de que el estado predeterminado (mínimo) sea un clúster de cero nodos.</span><span class="sxs-lookup"><span data-stu-id="068b3-174">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="068b3-175">Con esta configuración, el clúster empieza con cero nodos y solo se escala verticalmente si detecta trabajos en la cola.</span><span class="sxs-lookup"><span data-stu-id="068b3-175">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="068b3-176">Si el proceso de puntuación de Batch solo se produce algunas veces al día o menos, esta configuración permite obtener importantes ahorros.</span><span class="sxs-lookup"><span data-stu-id="068b3-176">If the batch scoring process only happens a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="068b3-177">Es posible que el escalado no sea apropiado para los trabajos por lotes que realizan con muy poco tiempo de diferencia entre sí.</span><span class="sxs-lookup"><span data-stu-id="068b3-177">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="068b3-178">El tiempo que tarda un clúster en agilizarse y ralentizarse también incurre en costos, por tanto, si una carga de trabajo por lotes empieza solo unos minutos después de que el trabajo anterior termine, puede resultar más rentable mantener el clúster en ejecución entre los trabajos.</span><span class="sxs-lookup"><span data-stu-id="068b3-178">The time that it takes for a cluster to spin up and spin down also incur a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="068b3-179">Eso depende de si los procesos de puntuación están programados para ejecutarse con mucha frecuencia (por ejemplo, cada hora), o con poca (por ejemplo, una vez al mes).</span><span class="sxs-lookup"><span data-stu-id="068b3-179">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="068b3-180">Implementación de la solución</span><span class="sxs-lookup"><span data-stu-id="068b3-180">Deploy the solution</span></span>

<span data-ttu-id="068b3-181">Hay disponible una implementación de referencia de esta arquitectura en [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="068b3-181">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="068b3-182">Para crear una solución escalable que permita puntuar muchos modelos en paralelo mediante Batch AI, siga los pasos de la configuración.</span><span class="sxs-lookup"><span data-stu-id="068b3-182">Follow the setup steps there to build a scalable solution for scoring many models in parallel using Batch AI.</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[batch-ai]: /azure/batch-ai/
[bai-file-server]: /azure/batch-ai/resource-concepts#file-server
[create-resources]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Azure/BatchAIAnomalyDetection
[logic-apps]: /azure/logic-apps/logic-apps-overview
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/sched/submit_jobs.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
